:toc: auto
:toc-position: left
:toclevels: 3

= Cloud Computing

== Models du cloud computing
=== IaaS
	Hyper convergence une approche du Datacenter qui rassemble et banalise des fonctions et services dans une même solution.

	IaaS (Infrastructure as a Service) propose à l'utilisateur un socle d’infrastructure informatique virtualisé, distribué et en grande partie automatisé. Un tel outil permet de mettre en production des applications utilisées par la DSI ou les services métiers.
	Serveurs, réseaux, stockage : le prestataire met au service de la DSI l'ensemble des ressources d'infrastructures nécessaire au fonctionnement d'une application, avec différents niveaux de service.

	Comment?
	L’unité de consommation sera la machine virtuelle, équipée de CPU, de mémoire et de stockage. La facturation sera comptabilisée sur le temps d’utilisation, et de sa consommation en nombre d’entrées sorties stockage et réseau.

	Le bénéfice ? Ces offres permettent aux DSI de se concentrer sur le développement applicatif sans avoir à gérer des infrastructure, et leurs évolutions.

=== Paas
	Pour les développeurs, la mise à disposition d'une plateforme de développement sur une couche initiale d'IaaS permet un gain de temps et des possibilités de test applicatifs, trop complexes à mettre en oeuvre en interne. C'est ce que propose le PaaS (Platform as a Service).
	Gestion des machines virtuelles, du middleware, du monitoring : tout est pris en charge de manière à assurer à l'utilisateur un confort d'usage digne de... l'énergie électrique. On appuie sur un bouton, et ça marche.

	Slide SaaS:
	Un logiciel sans prise de tête
	Enfin, le SaaS est tout simplement un logiciel mis à disposition à distance par un éditeur. L'utilisateur installe un client sur sa machine pour utiliser la solution, ou y accède via un navigateur web. Il n'a pas a se préoccuper de la plate-forme d’infrastructure ou de la plate-forme logicielle. Là aussi, le client paie l'utilisation de la solution en fonction de sa consommation.

	Alternative directe et crédible au mode de déploiement traditionnel de logiciels, il évite à la DSI d'avoir à mettre en place et à exploiter la solution (mise à jour et installation de correctifs entre autres).

=== Docker
	1- Comment résumer ce qu'est Docker ?

	Docker permet d'embarquer une application dans un container virtuel qui pourra s'exécuter sur n'importe quel machine. D'abord optimisé pour Linux, il l'est désormais pour Windows Server. C'est une technologie qui a pour but de faciliter les déploiements d'application, et la gestion du dimensionnement de l'infrastructure sous-jacente. Elle est en partie proposée en open source (sous licence Apache 2.0) par une société américaine, également appelée Docker, qui a été lancée par un Français : Solomon Hykes.

	2- Quelle différence avec la virtualisation traditionnelle ?

	La virtualisation traditionnelle permet, via un hyperviseur, de simuler une ou plusieurs machines physiques, et les exécuter sous forme de machines virtuelles (VM) sur un serveur ou un terminal. Ces VM intègrent elles-mêmes un OS sur lequel les applications qu'elles contiennent sont exécutées. Ce n'est pas le cas du container. Le container fait en effet directement appel à l'OS de sa machine hôte pour réaliser ses appels système et exécuter ses applications. Historiquement, Docker repose sur le format de containers Linux, alias LXC. Il l'étend par le biais d'une API dans l'optique d'exécuter les applications dans des containers standards, qui sont donc portables d'un serveur Linux à l'autre.

	Grâce à Docker, il est possible de containériser une application, avec pour chaque couche des containers isolant ses composants. C'est le concept d'architecture de microservices.
	6- La technologie Docker est-elle capable de passer à l'échelle sur des architectures en grappe ?

	Pour gérer une architecture de containers en cluster, Docker a développé Swarm. L'enjeu : étendre la portabilité, au-delà d'un container unitaire, à toute une architecture de containers en cluster. Docker a parallèlement introduit dans son orchestrateur tous les processus nécessaires à la production à grande échelle (équilibrage de charge, gestion de la résilience, du chiffrement des transactions entre les nœuds...).

	Mais en matière de performance, la société de San Francisco veut aller encore plus loin. Elle a acquis début 2016 la start-up Conductant qui s'est illustrée dans le développement d'Apache Aurora. Un système de clustering qui est conçu pour gérer des applications atteignant des centaines de millions d'utilisateurs. Toujours pour faciliter le déploiement des architectures en container, Docker propose, aussi, une console graphique de pilotage (Docker Universal Control Plane) et des outils de sécurité (notamment Trusted Registry, ou Docker Secrets qui gère l'intégrité d'un container tout au long de son cycle de vie). Toutes ces briques s'inscrivent dans une plateforme dite de Containers as a Service (CaaS), baptisée Docker Datacenter (DDC), visant à assurer le pilotage complet d'un cloud orienté containers (en recouvrant les processus de build, ship et run). Enfin, Docker a aussi acquis fin 2014 la plateforme cloud Tutum : un environnement SaaS conçu pour piloter le déploiement d'applications containerisées sur divers clouds publics (Microsoft Azure, Digital Ocean, Amazon Web Services et IBM SoftLayer).


	11- Quels sont les composants proposés par Docker en open source ?

	Docker a publié une dizaine de composants sous licence Apache (voir le graphique ci-dessous). Des composants qui recouvrent les principales fonctionnalités nécessaires au pilotage d'une architecture containérisée :
	- gestion du réseau,
	- du stockage, de la sécurité... Parmi eux figure containerd.
	Une brique centrale de la technologie Docker puisqu'elle permet l'exécution du container. Considérant la criticité de cette brique en vue de la standardisation des offres de container, Docker en a reversé les droits à une organisation indépendante (la Cloud Native Computing Foundation). En avril 2017, l'éditeur est allé un peu plus loin dans la démarche en lançant Moby : un framework open source dessiné pour construire des systèmes de container. Il comprend 80 composants open source : ceux de Docker (containerd, swarmkit...) mais aussi d'autres projets (Redis, Nginx...). Moby se veut être un projet participatif, à travers lequel tous les acteurs de la communauté Docker construisant des solutions à base de container peuvent partager des briques.

=== Surikator
	Le projet nommé Surikator est une application open source développée en langage Go et conteneurisé dans un container docker linux c’est-à-dire optimiser pour la plateforme linux. Surikator en un mot est un middleware qui mesure les ressources systèmes, les métriques et les logs d’un container docker pour produire un monitoring. Pour la réalisation du projet, il est nécessaire d’avoir une compétence dans les technologies nouvelles tel que :
		Une compétence sur Docker,
		Go langage (Google),
		Bonne compétence en Linux, notamment Ubuntu,
		Script Bash,
		Et les outils d’intégration, notamment Jenkins.
	Le développement du projet en tant que service se repose sur l’approche diviser pour mieux régner dans le but de pouvoir apporter une optimisation à l’avenir sans avoir à impacter le reste du code. Pour cela, Surikator est décomposé en trois microservice distincts, dont chaque microservice à son propre rôle.

		Amélioration de l’évaluation de la performance des processus et de l’aptitude à at-teindre les objectifs notamment sur les tests effectués,
		Amélioration de l’efficacité et de l’efficience opérationnelles,
		Plus grande aptitude à passer en revue, remettre en question et changer les opi-nions et les décisions,
		Plus grande aptitude à démontrer l’efficacité de décisions antérieures,
		Prendre des décisions et entreprendre des actions fondées sur des preuves, tout en tenant compte de l’expérience et de l’intuition.
