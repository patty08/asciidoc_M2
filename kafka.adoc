:toc: auto
:toc-position: left
:toclevels: 3

= Kafka
Patsoo08 <patty.randri8@gmail.com>

image::./img/kafkaProducer_1.png[Producer,1024,480,pdfwidth=50%,scaledwidth=50%,float="right",align="center"]

== EXPORT variable

export ZOO=

Tester ZOOKEEPER:

nc -vz [zookeper:port]

== les topics
Vous pouvez créer un nouveau sujet Kafka nommé my-topic comme suit:

	kafka-topics --create --zookeeper localhost: 2181 --replication-factor 1 --partitions 3 --topic my-topic

Vous pouvez vérifier que le sujet my-topic a été créé avec succès en répertoriant tous les topics disponibles:

	kafka-topics --list --zookeeper localhost: 2181

Vous pouvez ajouter plus de partitions comme suit:

	kafka-topics --zookeeper localhost: 2181 --alter --topic my-topic --partitions 16

Vous pouvez supprimer un sujet nommé my-topic comme suit:

	kafka-topics --zookeeper localhost: 2181 --delete --topic my-topic

Vous pouvez trouver plus de détails sur un sujet nommé cc_payments comme suit:

	kafka-topics --describe --zookeeper localhost: 2181 --topic cc_payments

Vous pouvez voir les partitions sous-répliquées pour tous les topics comme suit:

	kafka-topics --zookeeper localhost: 2181 / kafka-cluster --describe --under-replicated-partitions

== Producteurs
Vous pouvez produire des messages à partir d'une entrée standard comme suit:

	kafka-console-producteur --broker-list localhost: 9092 --topic my-topic

Vous pouvez produire de nouveaux messages à partir d'un fichier existant nommé messages.txt comme suit:

	kafka-console-producteur --broker-list localhost: 9092 - test de sujet <messages.txt

Vous pouvez produire des messages Avro comme suit:
	
kafka-avro-console-producteur --broker-list localhost: 9092 --topic my.Topic --property value.schema = '{"type": "record", "name": "myrecord", "fields": [{"nom": "f1", "type": "chaîne"}]} '--property 
schema.registry.url = http: // localhost: 8081
Vous pouvez entrer quelques nouvelles valeurs à partir de la console comme suit:

{"f1": "value1"}


== Consumers

Consommer des messages
Vous pouvez commencer un consommateur depuis le début du journal comme suit:

	kafka-console-consumer --bootstrap-server localhost: 9092 --topic my-topic --from-begin

> Commande important après avoir supprimer un topic pour le reinitialiser par la suite

Vous pouvez consommer un seul message comme suit:

	kafka-console-consumer --bootstrap-server localhost: 9092 --topic my-topic --max-messages 1

Vous pouvez consommer un seul message de __consumer_offsets comme suit:

	kafka-console-consumer --bootstrap-server localhost: 9092 --topic __consumer_offsets --formatter 'kafka.coordinator.GroupMetadataManager $ OffsetsMessageFormatter' --max-messages 1

Vous pouvez consommer et spécifier un groupe de consommateurs comme suit:

	kafka-console-consumer --topic my-topic --new-consumer --bootstrap-server localhost: 9092 --consumer-property group.id = my-group

Consommer des messages Avro
Vous pouvez utiliser 10 messages Avro à partir d'un sujet nommé position-reports comme suit:

	kafka-avro-console-consumer - rapports de position du sujet --new-consumer --bootstrap-server localhost: 9092 --from-starting --property schema.registry.url = localhost: 8081 --max-messages 10

Vous pouvez consommer tous les messages Avro existants à partir d'un sujet nommé position-reports comme suit:

	kafka-avro-console-consumer - rapports de position de sujet --new-consumer --bootstrap-server localhost: 9092 --from-starting --property schema.registry.url = localhost: 8081

Opérations d'administration des consommateurs
Vous pouvez répertorier tous les groupes comme suit:

	kafka-consumer-groups --new-consumer --list --bootstrap-server localhost: 9092

Vous pouvez décrire un groupe nommé testgroup comme suit:

	kafka-consumer-groups --bootstrap-server localhost: 9092 --describe --group testgroup


== Config
Vous pouvez définir la rétention d'un sujet comme suit:

	kafka-configs --zookeeper localhost: 2181 --alter - rubriques de type entité - nom-entité my-topic --add-config retention.ms = 3600000

Vous pouvez imprimer tous les remplacements de configuration pour un sujet nommé my-topic comme suit:

	kafka-configs --zookeeper localhost: 2181 --describe --entity-type topics --entity-name my-topic

Vous pouvez supprimer un remplacement de configuration pour retention.ms pour un sujet nommé my-topic comme suit:

	kafka-configs --zookeeper localhost: 2181 --alter - rubriques de type entité - nom-entité my-topic --delete-config retention.ms

Performance
Bien que Kafka soit assez rapide par conception, il est bon de pouvoir tester ses performances. Vous pouvez vérifier les performances de production de Kafka comme suit:

	kafka-producteur-perf-test - rapports de position des topics - débit 10000 - taille d'enregistrement 300 - nombre d'enregistrements 20000 - accessoires de production bootstrap.servers = "localhost: 9092"



== ACL
Vous pouvez ajouter une nouvelle ACL de consommateur à un sujet existant comme suit:

	kafka-acls --authorizer-properties zookeeper.connect = localhost: 2181 --add --allow-principal Utilisateur: Bob --consumer - topic topicA --group groupA

Vous pouvez ajouter une nouvelle ACL de producteur à un sujet existant comme suit:

	kafka-acls --authorizer-properties zookeeper.connect = localhost: 2181 --add --allow-principal User: Bob --producer --topic topicA

Vous pouvez répertorier les ACL d'un sujet nommé topicA comme suit:

	kafka-acls --authorizer-properties zookeeper.connect = localhost: 2181 --list --topic topicA


== Zookeeper
Vous pouvez entrer dans le shell zookeeper comme suit:

	zookeeper-shell localhost: 2182 ls


== TOOLS:

CMAK: https://github.com/yahoo/CMAK

Burrow : https://github.com/linkedin/Burrow


== Docker

	docker run -it --rm  -p 9000:9000 -e ZK_HOSTS="your-zk.domain:2181" -e APPLICATION_SECRET=letmein -e KM_ARGS=-Djava.net.preferIPv4Stack=true sheepkiller/kafka-manager 

ou

	docker run -d --name kafka-manager -p 9000:9000 \
	-e ZK_HOSTS="alpha:2181,beta:2181,gamma:2181" \
	--restart always \
	--log-driver json-file --log-opt max-size=10m \
	sheepkiller/kafka-manager -Djava.net.preferIPv4Stack=true


=== Activer JMX
JMX doit être activé pour les afficher dans kafka-manager.


	KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote \
	  -Dcom.sun.management.jmxremote.authenticate = false \
	  -Dcom.sun.management.jmxremote.ssl = false \
	  -Djava.rmi.server.hostname = {{ansible_hostname}} \
	  -Dcom.sun.management.jmxremote.rmi.port = 9099 "
	JMX_PORT: 9099

Faites attention au port JMX exposé. Vous pouvez choisir n'importe quel port. Je pense que le port 9099 convient, car le port exposé par défaut est 9092.


== Docker compose

	version: '3.1'
	
	services:
	  zookeeper:
	    container_name: zookeeper
	    image: zookeeper:3.4
	    restart: on-failure
	    volumes:
	      - "./zookeeper/data:/data"
	      - "./zookeeper/logs:/datalog"
	    ports:
	      - "2181:2181"
	    network_mode: "host"
	
	  kafka:
	    container_name: kafka
	    image: wurstmeister/kafka:1.0.0
	    restart: on-failure
	    depends_on:
	      - zookeeper
	    volumes:
	      - /var/run/docker.sock:/var/run/docker.sock
	    environment:
	      - KAFKA_ZOOKEEPER_CONNECT=${EXPOSED_HOSTNAME}:2181
	      - KAFKA_ADVERTISED_HOST_NAME=${EXPOSED_HOSTNAME}
	      - JMX_PORT=9093
	      - KAFKA_ADVERTISED_PORT=9092
	      - KAFKA_DELETE_TOPIC_ENABLE=true
	      - KAFKA_LOG_RETENTION_HOURS=1
	      - KAFKA_MESSAGE_MAX_BYTES=10000000
	      - KAFKA_REPLICA_FETCH_MAX_BYTES=10000000
	      - KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS=60000
	      - KAFKA_NUM_PARTITIONS=2
	      - KAFKA_DELETE_RETENTION_MS=1000
	    ports:
	      - "9092:9092"
	      - "9093:9093"
	    network_mode: "host"
	
	  kafka-manager:
	    container_name: kafka-manager
	    image: hlebalbau/kafka-manager:1.3.3.16
	    restart: on-failure
	    depends_on:
	      - kafka
	      - zookeeper
	    command: -Dconfig.file=/kafka-manager/conf/application.conf -Dapplication.home=/kafkamanager
	    ou 
	    command: -Dpidfile.path=/dev/null
	    environment:
	      - ZK_HOSTS=${EXPOSED_HOSTNAME}
	      - APPLICATION_SECRET=letmein
	    ports:
	      - "9000:9000"
	    network_mode: "host"


	https://www.playframework.com/documentation/2.7.x/ProductionConfiguration#Changing-the-path-of-RUNNING_PID

== tricks

	https://dev.to/thegroo/one-to-run-them-all-1mg6

	https://jrblog.pentaidea.com/john/2019/03/29/build-3-nodes-1-cluster-kafka-zookeeper-kafka-manager-envirnment-by-docker-compose/